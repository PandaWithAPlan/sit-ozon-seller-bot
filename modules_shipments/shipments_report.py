# modules_sales/sales_report.py
from __future__ import annotations

import os
import time
import datetime as dt
from typing import List, Tuple, Dict, Any, Optional, Iterable
import html
import requests
from dotenv import load_dotenv

# ‚îÄ‚îÄ‚îÄ ENV ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
load_dotenv(os.path.join(BASE_DIR, ".env"))

OZON_CLIENT_ID = os.getenv("OZON_CLIENT_ID", "")
OZON_API_KEY = os.getenv("OZON_API_KEY", "")
OZON_COMPANY_ID = os.getenv("OZON_COMPANY_ID")  # –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º
WATCH_SKU_RAW = os.getenv("WATCH_SKU", "")

# ‚ö†Ô∏è –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ –ø–æ WATCH_OFFERS:
# –ï—Å–ª–∏ PRODUCTS_MODE=OFFER, —Ç–æ –≤ –º–æ–¥—É–ª—è—Ö, –∫–æ—Ç–æ—Ä—ã–µ –æ–±—Ä–∞—â–∞—é—Ç—Å—è –∫ analytics (—Ñ–∞–∫—Ç/–ø–ª–∞–Ω/—Ç—Ä–∞—Ñ–∏–∫),
# —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏–¥—ë—Ç –ø–æ offer_id –∏–∑ WATCH_OFFERS. –î–∞–Ω–Ω—ã–π –º–æ–¥—É–ª—å —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –æ—Ç—á—ë—Ç –ü–û –û–î–ù–û–ú–£ SKU,
# –ø–æ—ç—Ç–æ–º—É WATCH_OFFERS –∑–¥–µ—Å—å –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è; –∫–æ–Ω—Ç—Ä–æ–ª—å ¬´—á—É–∂–∏—Ö¬ª —é–Ω–∏—Ç–æ–≤ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω —á–µ—Ä–µ–∑ WATCH_SKU.

# –ù–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è ¬´–Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–≥–æ¬ª –∫–ª–∞—Å—Ç–µ—Ä–∞ (—Ä–∞–Ω—å—à–µ –±—ã–ª–æ ¬´–ù–µ —É–∫–∞–∑–∞–Ω¬ª)
UNKNOWN_CLUSTER = os.getenv("UNKNOWN_CLUSTER_TITLE", "–ë–µ–∑ –∫–ª–∞—Å—Ç–µ—Ä–∞")
# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–∫–∏ ¬´–ö–ª–∞—Å—Ç–µ—Ä¬ª –≤ –æ—Ç—á—ë—Ç–µ (–¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö –º–æ–∂–Ω–æ —É–º–µ–Ω—å—à–∏—Ç—å)
MAX_CLUSTER_NAME_W = int(os.getenv("SALES_REPORT_MAX_CLUSTER_NAME_W", "26"))

API_ANALYTICS = "https://api-seller.ozon.ru/v1/analytics/data"
API_CLUSTERS = "https://api-seller.ozon.ru/v1/cluster/list"
API_FBO_LIST = "https://api-seller.ozon.ru/v2/posting/fbo/list"  # v2
API_FBS_LIST = "https://api-seller.ozon.ru/v3/posting/fbs/list"  # v3
API_RETURNS = "https://api-seller.ozon.ru/v1/returns/list"  # –≤–æ–∑–≤—Ä FBO/FBS

# ‚îÄ‚îÄ‚îÄ HTTP ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
_SESSION = requests.Session()
_SESSION.headers.update({"User-Agent": "seller-bot/units-report/1.9"})
_MIN_INTERVAL_SEC = 0.5
_last_call_ts: float = 0.0


def _headers() -> Dict[str, str]:
    return {
        "Client-Id": OZON_CLIENT_ID,
        "Api-Key": OZON_API_KEY,
        "Content-Type": "application/json",
    }


def _throttle():
    global _last_call_ts
    now = time.time()
    if now - _last_call_ts < _MIN_INTERVAL_SEC:
        time.sleep(_MIN_INTERVAL_SEC - (now - _last_call_ts))
    _last_call_ts = time.time()


def _post(url: str, body: Dict[str, Any], timeout: int = 30) -> Dict[str, Any]:
    _throttle()
    r = _SESSION.post(url, headers=_headers(), json=body, timeout=timeout)
    r.raise_for_status()
    return r.json()


# ‚îÄ‚îÄ‚îÄ –ê–ª–∏–∞—Å—ã SKU ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
try:
    from .sales_facts_store import get_alias_for_sku  # type: ignore
except Exception:

    def get_alias_for_sku(sku: int) -> str:
        return str(sku)


# ‚îÄ‚îÄ‚îÄ –°–ø–∏—Å–æ–∫/–Ω–∞–±–æ—Ä –Ω–∞–±–ª—é–¥–∞–µ–º—ã—Ö SKU ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


def _parse_watch_skus(txt: str) -> List[int]:
    if not txt:
        return []
    parts = [p.strip() for p in txt.replace("\n", ",").replace(" ", ",").split(",")]
    out: List[int] = []
    for p in parts:
        if not p:
            continue
        try:
            out.append(int(p.split(":")[0]))
        except Exception:
            pass
    seen = set()
    uniq: List[int] = []
    for s in out:
        if s not in seen:
            uniq.append(s)
            seen.add(s)
    return uniq


def _allowed_sku_set() -> set[int]:
    """–ú–Ω–æ–∂–µ—Å—Ç–≤–æ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö SKU (—Å—Ç—Ä–æ–≥–∏–π —Ñ–∏–ª—å—Ç—Ä: —Ç–æ–ª—å–∫–æ –∏–∑ WATCH_SKU)."""
    return set(_parse_watch_skus(WATCH_SKU_RAW))


def list_skus(limit: int = 200) -> List[Tuple[int, str]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ (sku, alias) –î–õ–Ø –ú–ï–ù–Æ –≤ –ø–æ—Ä—è–¥–∫–µ WATCH_SKU.
    –ò–º—è –±–µ—Ä—ë—Ç—Å—è –∏–∑ ALIAS (—á–µ—Ä–µ–∑ get_alias_for_sku), –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ ‚Äî —Å–∞–º sku.
    –ò–Ω—ã–µ —é–Ω–∏—Ç—ã –≤ –º–µ–Ω—é –Ω–µ –ø–æ–ø–∞–¥–∞—é—Ç (–µ—Å–ª–∏ WATCH_SKU –∑–∞–¥–∞–Ω).
    """
    skus: List[int] = _parse_watch_skus(WATCH_SKU_RAW)
    if not skus:
        # –§–æ–ª–±—ç–∫: –∫–æ–≥–¥–∞ WATCH_SKU –ø—É—Å—Ç ‚Äî —Ä–∞–∑—Ä–µ—à–∏—Ç—å –≤—Å–µ, –Ω–æ —ç—Ç–æ –ø–æ–≤–µ–¥–µ–Ω–∏–µ ¬´–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é¬ª.
        try:
            from .sales_facts_store import all_skus  # type: ignore

            seen = set()
            for s in list(all_skus()):
                try:
                    si = int(s)
                except Exception:
                    continue
                if si not in seen:
                    seen.add(si)
                    skus.append(si)
        except Exception:
            pass

    pairs: List[Tuple[int, str]] = []
    for sku in skus:
        try:
            alias = get_alias_for_sku(int(sku)) or str(sku)
        except Exception:
            alias = str(sku)
        pairs.append((int(sku), alias))

    # ‚öôÔ∏è –í–ê–ñ–ù–û: –ù–ï —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∏–º–µ–Ω–∏ ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Ä—è–¥–æ–∫ WATCH_SKU.
    return pairs[:limit]


# ‚îÄ‚îÄ‚îÄ –£—Ç–∏–ª–∏—Ç—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


def _parse_date(s: str) -> dt.date:
    if "-" in s:
        return dt.date.fromisoformat(s)
    d, m, y = s.split(".")
    return dt.date(int(y), int(m), int(d))


def _analytics_period(start: str, end: str) -> tuple[str, str]:
    """
    –î–ª—è /v1/analytics/data –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω–µ—Ü –ü–ï–†–ò–û–î–ê –í–ö–õ–Æ–ß–ò–¢–ï–õ–¨–ù–û (–∫–∞–∫ –≤ UI).
    –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –æ–∫–∞–∂–µ—Ç—Å—è –ø—É—Å—Ç—ã–º, –ø–æ–∑–∂–µ —Å–¥–µ–ª–∞–µ–º —Ä–µ—Ç—Ä–∞–π —Å–æ —Å–¥–≤–∏–≥–æ–º +1 –¥–µ–Ω—å.
    """
    ds = _parse_date(start)
    de = _parse_date(end)
    if de < ds:
        ds, de = de, ds
    return ds.isoformat(), de.isoformat()


def _to_z(d: dt.date, end_of_day: bool = False) -> str:
    return f"{d.isoformat()}T{'23:59:59.999' if end_of_day else '00:00:00.000'}Z"


def _fmt_int(n: int) -> str:
    return f"{n:,}".replace(",", " ")


def _pad(s: str, width: int) -> str:
    return s[: width - 1] + "‚Ä¶" if len(s) > width else s.ljust(width)


def _pre_block(text: str) -> str:
    return f"<pre>{html.escape(text, quote=False)}</pre>"


def _pre_kv(pairs: List[Tuple[str, str]]) -> str:
    """–í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è ¬´—Ç–∞–±–ª–∏—Ü–∞¬ª: –∫–ª—é—á–∏ —Å–ª–µ–≤–∞, –∑–Ω–∞—á–µ–Ω–∏—è —Å–ø—Ä–∞–≤–∞, –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –ø–æ –∫–æ–ª–æ–Ω—É –∫–ª—é—á–∞."""
    if not pairs:
        return _pre_block("")
    key_w = max(len(k) for k, _ in pairs)
    lines = [f"{k.ljust(key_w)}  {v}" for k, v in pairs]
    return _pre_block("\n".join(lines))


def _as_int_maybe(x: Any) -> Optional[int]:
    try:
        return int(str(x))
    except Exception:
        return None


# –°–æ–∫—Ä–∞—â–µ–Ω–∏–µ –¥–ª–∏–Ω–Ω—ã—Ö –∏–º—ë–Ω –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–ª—è –∫–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç–∏


def _shorten_cluster(name: str) -> str:
    s = str(name or "")
    repl = {
        "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥": "–°–ü–±",
        "–î–∞–ª—å–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω—ã": "–î–†",
        "–°–µ–≤–µ—Ä–æ-–ó–∞–ø–∞–¥": "–°–ó–§–û",
        "–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π": "–¶–µ–Ω—Ç—Ä",
        "–î–∞–ª—å–Ω–µ–≤–æ—Å—Ç–æ—á–Ω—ã–π": "–î–í",
        ",": " ",
        "  ": " ",
        " –∏ ": "+",
        " ,": " ",
        ", ": " ",
    }
    for k, v in repl.items():
        s = s.replace(k, v)
    while "  " in s:
        s = s.replace("  ", " ")
    s = s.strip()
    if not s:
        s = UNKNOWN_CLUSTER
    return s


# ‚îÄ‚îÄ‚îÄ –ö–ª–∞—Å—Ç–µ—Ä—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
_clusters_cache: Optional[Dict[int, str]] = None  # warehouse_id -> cluster_name


def _load_clusters() -> Dict[int, str]:
    global _clusters_cache
    if _clusters_cache is not None:
        return _clusters_cache

    mapping: Dict[int, str] = {}
    # –†–§ + –°–ù–ì, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å ¬´–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω¬ª –∏ ¬´–ë–µ–ª–∞—Ä—É—Å—å¬ª
    for cluster_type in ("CLUSTER_TYPE_OZON", "CLUSTER_TYPE_CIS"):
        try:
            js = _post(API_CLUSTERS, {"cluster_type": cluster_type})
        except Exception:
            continue
        for cl in js.get("clusters", []) or []:
            name = cl.get("name") or UNKNOWN_CLUSTER
            for lc in cl.get("logistic_clusters", []) or []:
                for wh in lc.get("warehouses", []) or []:
                    wid = wh.get("warehouse_id")
                    if isinstance(wid, int):
                        mapping[wid] = name
    _clusters_cache = mapping
    return mapping


# ‚îÄ‚îÄ‚îÄ –ü–æ—Å—Ç–∏–Ω–≥–∏ FBO/FBS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


def _iter_postings(
    url: str, since_iso: str, to_iso: str, limit: int = 500
) -> Iterable[Dict[str, Any]]:
    offset = 0
    while True:
        body = {
            "dir": "ASC",
            "filter": {"since": since_iso, "to": to_iso, "status": ""},
            "limit": limit,
            "offset": offset,
            "with": {"analytics_data": True, "financial_data": True},
        }
        js = _post(url, body)
        if url.endswith("/v2/posting/fbo/list"):
            items = js.get("result") or []
            has_next = len(items) == limit
        else:
            res = js.get("result") or {}
            items = res.get("postings") or []
            has_next = bool(res.get("has_next"))
        for it in items:
            yield it
        if not has_next:
            break
        offset += limit


def _cluster_from_posting(p: Dict[str, Any], wh2cluster: Dict[int, str]) -> str:
    """
    –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å warehouse_id –∏–∑ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç –ø–æ—Å—Ç–∏–Ω–≥–∞
    –∏ —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å –µ–≥–æ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º –∫–ª–∞—Å—Ç–µ—Ä–∞.
    """
    # 1) analytics_data.warehouse_id (—Å–∞–º—ã–π –Ω–∞–¥—ë–∂–Ω—ã–π)
    a = p.get("analytics_data") or {}
    wid = _as_int_maybe(a.get("warehouse_id"))
    if isinstance(wid, int) and wid in wh2cluster:
        return wh2cluster[wid]

    # 2) shipment_warehouse_id (–≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ FBS)
    wid = _as_int_maybe(p.get("shipment_warehouse_id"))
    if isinstance(wid, int) and wid in wh2cluster:
        return wh2cluster[wid]

    # 3) delivery_method.warehouse_id (–∏–Ω–æ–≥–¥–∞ –±—ã–≤–∞–µ—Ç –≤ v3)
    dm = p.get("delivery_method") or {}
    wid = _as_int_maybe(dm.get("warehouse_id"))
    if isinstance(wid, int) and wid in wh2cluster:
        return wh2cluster[wid]

    # 4) fallback: –∫–æ—Ä–Ω–µ–≤–æ–π warehouse_id (—Ä–µ–¥–∫–æ)
    wid = _as_int_maybe(p.get("warehouse_id"))
    if isinstance(wid, int) and wid in wh2cluster:
        return wh2cluster[wid]

    return UNKNOWN_CLUSTER


# ‚îÄ‚îÄ‚îÄ –í–æ–∑–≤—Ä–∞—Ç—ã FBO/FBS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


def _iter_returns(time_from: str, time_to: str, limit: int = 500) -> Iterable[Dict[str, Any]]:
    """
    –ü–∞–≥–∏–Ω–∞—Ü–∏—è –ø–æ last_id. –§–∏–ª—å—Ç—Ä –ø–æ logistic_return_date (–≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ –ø–æ –≤—Ä–µ–º–µ–Ω–∏).
    """
    last_id: Optional[int] = None
    while True:
        body = {
            "filter": {
                "logistic_return_date": {
                    "time_from": time_from,
                    "time_to": time_to,
                }
            },
            "limit": limit,
        }
        if last_id:
            body["last_id"] = last_id
        js = _post(API_RETURNS, body)
        items = js.get("returns") or []
        for it in items:
            yield it
        if not js.get("has_next"):
            break
        try:
            last_id = int(items[-1].get("id"))
        except Exception:
            break


def _cluster_from_return(
    r: Dict[str, Any],
    wh2cluster: Dict[int, str],
    posting2cluster: Dict[str, str],
) -> str:
    """
    –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–ª–∞—Å—Ç–µ—Ä –≤–æ–∑–≤—Ä–∞—Ç–∞:
      1) place.id
      2) target_place.id
      3) –ø–æ posting_number —á–µ—Ä–µ–∑ —Ä–∞–Ω–µ–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–π posting2cluster
    """
    # 1) place.id
    place = r.get("place") or {}
    wid = _as_int_maybe(place.get("id"))
    if isinstance(wid, int) and wid in wh2cluster:
        return wh2cluster[wid]

    # 2) target_place.id
    tplace = r.get("target_place") or {}
    wid = _as_int_maybe(tplace.get("id"))
    if isinstance(wid, int) and wid in wh2cluster:
        return wh2cluster[wid]

    # 3) posting_number ‚Üí –∫–ª–∞—Å—Ç–µ—Ä –∏–∑ –ø–æ—Å—Ç–∏–Ω–≥–æ–≤
    pn = r.get("posting_number")
    if pn and pn in posting2cluster:
        return posting2cluster[pn]

    return UNKNOWN_CLUSTER


# ‚îÄ‚îÄ‚îÄ –°–±–æ—Ä –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


def _collect_clusters_for_sku(sku: int, start: str, end: str) -> Dict[str, Dict[str, int]]:
    """
    –°—á–∏—Ç–∞–µ–º –∑–∞–∫–∞–∑–∞–Ω–Ω—ã–µ —é–Ω–∏—Ç—ã –¢–ê–ö –ñ–ï, –∫–∞–∫ –≤ –∞–Ω–∞–ª–∏—Ç–∏–∫–µ:
    - ordered   ‚Äî –≤—Å–µ –∑–∞–∫–∞–∑–∞–Ω–Ω—ã–µ —é–Ω–∏—Ç—ã (–≤–∫–ª—é—á–∞—è –æ—Ç–º–µ–Ω—ë–Ω–Ω—ã–µ/–≤–æ–∑–≤—Ä–∞—Ç—ã);
    - cancelled ‚Äî –æ—Ç–¥–µ–ª—å–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–º–µ–Ω—ë–Ω–Ω—ã—Ö;
    - returned  ‚Äî –æ—Ç–¥–µ–ª—å–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–∑–≤—Ä–∞—â—ë–Ω–Ω—ã—Ö (–∏–∑ /v1/returns/list);
    –¢–æ–≥–¥–∞ –ò–¢–û–ì = ordered - cancelled - returned.
    """
    ds = _parse_date(start)
    de = _parse_date(end)
    since = _to_z(ds)
    to_eod = _to_z(de, end_of_day=True)

    wh2cluster = _load_clusters()
    out: Dict[str, Dict[str, int]] = {}

    def bump(cl: str, k: str, v: int):
        row = out.setdefault(cl, {"ordered": 0, "cancelled": 0, "returned": 0})
        row[k] += int(v)

    # –±—É–¥–µ–º –∫–æ–ø–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ posting_number -> cluster –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –º–∞—Ç—á–∏–Ω–≥–∞ –≤–æ–∑–≤—Ä–∞—Ç–æ–≤
    posting2cluster: Dict[str, str] = {}

    # 1) –ü–æ—Å—Ç–∏–Ω–≥–∏: —Å—á–∏—Ç–∞–µ–º ordered –∏ cancelled
    for url in (API_FBO_LIST, API_FBS_LIST):
        try:
            for p in _iter_postings(url, since, to_eod):
                st = (p.get("status") or "").lower()
                cluster = _cluster_from_posting(p, wh2cluster)

                # —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å posting_number -> cluster (–µ—Å–ª–∏ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å)
                pn = p.get("posting_number")
                if cluster != UNKNOWN_CLUSTER and isinstance(pn, str) and pn:
                    posting2cluster[pn] = cluster

                for pr in p.get("products", []) or []:
                    try:
                        p_sku = int(pr.get("sku") or 0)
                    except Exception:
                        continue
                    if p_sku != int(sku):
                        continue
                    q = int(pr.get("quantity") or 0)

                    # ¬´–ó–∞–∫–∞–∑–∞–Ω–æ¬ª –≤—Å–µ–≥–¥–∞ —Ä–∞—Å—Ç—ë—Ç
                    bump(cluster, "ordered", q)

                    # –û—Ç–º–µ–Ω—ã ‚Äî –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ
                    if st == "cancelled":
                        bump(cluster, "cancelled", q)
        except requests.HTTPError as e:
            if getattr(e.response, "status_code", None) in (403, 404):
                continue
            raise
        except Exception:
            continue

    # 2) –í–æ–∑–≤—Ä–∞—Ç—ã: –∏–∑ /v1/returns/list (–ø–æ logistic_return_date)
    try:
        for r in _iter_returns(since, to_eod):
            pr = r.get("product") or {}
            try:
                r_sku = int(pr.get("sku") or 0)
            except Exception:
                continue
            if r_sku != int(sku):
                continue
            qty = int(pr.get("quantity") or 0)

            cluster = _cluster_from_return(r, wh2cluster, posting2cluster)
            bump(cluster, "returned", qty)
    except Exception:
        # –í–æ–∑–≤—Ä–∞—Ç—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã ‚Äî –Ω–µ –ø–∞–¥–∞–µ–º, –ø—Ä–æ—Å—Ç–æ –æ—Å—Ç–∞—é—Ç—Å—è 0
        pass

    return out


# ‚îÄ‚îÄ‚îÄ –ê–Ω–∞–ª–∏—Ç–∏–∫–∞: —Ç–æ—á–Ω—ã–µ totals –ø–æ SKU ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


def _analytics_sum_rows(rows: list, sku: int) -> Dict[str, int]:
    total_ord = total_cnc = total_ret = 0
    sku_str = str(sku)
    for r in rows:
        dims = r.get("dimensions") or []
        if not any(str(d.get("id", "")) == sku_str for d in dims):
            continue
        m = r.get("metrics") or []
        if isinstance(m, list):
            if len(m) >= 1:
                total_ord += int(m[0] or 0)
            if len(m) >= 2:
                total_cnc += int(m[1] or 0)
            if len(m) >= 3:
                total_ret += int(m[2] or 0)
        elif isinstance(m, dict):
            total_ord += int(m.get("ordered_units", 0) or 0)
            total_cnc += int(m.get("cancellations", 0) or 0)
            total_ret += int(m.get("returns", 0) or 0)
    return {"ordered_units": total_ord, "cancellations": total_cnc, "returns": total_ret}


def _analytics_query_rows(sku: int, date_from: str, date_to: str) -> list:
    """dimension=['day','sku'] + –ø–∞–≥–∏–Ω–∞—Ü–∏—è, —Ç—è–Ω–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–π SKU (—á–µ—Ä–µ–∑ —Ñ–∏–ª—å—Ç—Ä –∏ –ø–æ—Å—Ç-—Ñ–∏–ª—å—Ç—Ä)."""
    rows: list = []
    offset = 0
    limit = 1000
    while True:
        body = {
            "date_from": date_from,
            "date_to": date_to,
            "metrics": ["ordered_units", "cancellations", "returns"],
            "dimension": ["day", "sku"],
            "filters": [{"key": "sku", "value": str(sku)}],
            "limit": limit,
            "offset": offset,
        }
        if OZON_COMPANY_ID and OZON_COMPANY_ID.isdigit():
            body["company_id"] = int(OZON_COMPANY_ID)
        js = _post(API_ANALYTICS, body)
        chunk = (
            (js.get("result", {}) or {}).get("data")
            or (js.get("result", {}) or {}).get("rows")
            or []
        )
        rows.extend(chunk)
        if len(chunk) < limit:
            break
        offset += limit
    return rows


def _fetch_analytics_totals(sku: int, start: str, end: str) -> Dict[str, int]:
    # —Å–Ω–∞—á–∞–ª–∞ ‚Äî ¬´–∫–∞–∫ –≤ UI¬ª (–∫–æ–Ω–µ—Ü –ø–µ—Ä–∏–æ–¥–∞ –≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ)
    df, dt_incl = _analytics_period(start, end)
    rows = _analytics_query_rows(sku, df, dt_incl)
    totals = _analytics_sum_rows(rows, sku)
    if any(v != 0 for v in totals.values()):
        return totals

    # –µ—Å–ª–∏ –≤–¥—Ä—É–≥ –ø—É—Å—Ç–æ ‚Äî —Ä–µ—Ç—Ä–∞–π –ø–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–ø–æ–ª—É–∏–Ω—Ç–µ—Ä–≤–∞–ª [from, to) )
    try:
        dt_semi = (_parse_date(end) + dt.timedelta(days=1)).isoformat()
        rows2 = _analytics_query_rows(sku, df, dt_semi)
        return _analytics_sum_rows(rows2, sku)
    except Exception:
        return {"ordered_units": 0, "cancellations": 0, "returns": 0}


# ‚îÄ‚îÄ‚îÄ –¢–∞–±–ª–∏—á–Ω—ã–π —Ä–µ–Ω–¥–µ—Ä (–∫–æ–º–ø–∞–∫—Ç–Ω—ã–π, —á–∏—Å–ª–∞ —Å—Ç–æ–ª–±—Ü–∞–º–∏) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


def _pre_table(headers: List[str], rows: List[List[str]], max_name_w: int) -> str:
    """
    –†–∏—Å—É–µ–º –º–æ–Ω–æ—à–∏—Ä–∏–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É:
      ‚Ä¢ –ø–µ—Ä–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞ ‚Äî ¬´–ö–ª–∞—Å—Ç–µ—Ä¬ª (–æ–±—Ä–µ–∑–∞–µ–º/–ø–∞–¥–¥–∏–º –¥–æ max_name_w);
      ‚Ä¢ –æ—Å—Ç–∞–ª—å–Ω—ã–µ ‚Äî —á–∏—Å–ª–æ–≤—ã–µ, –ø—Ä–∏–∂–∞—Ç—ã –≤–ø—Ä–∞–≤–æ –∏ –≤—ã—Ä–æ–≤–Ω–µ–Ω—ã –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º;
      ‚Ä¢ –º–µ–∂–¥—É –∫–æ–ª–æ–Ω–∫–∞–º–∏ –æ–¥–∏–Ω –ø—Ä–æ–±–µ–ª.
    """
    if not rows:
        return _pre_block("‚Äî")

    # —à–∏—Ä–∏–Ω—ã —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
    num_cols = list(zip(*[r[1:] for r in rows])) if rows else []
    num_w = [max(len(h), max(len(v) for v in col)) for h, col in zip(headers[1:], num_cols)]

    # –∑–∞–≥–æ–ª–æ–≤–æ–∫
    name_h = _pad(headers[0], max_name_w)
    head_cells = [name_h] + [h.rjust(w) for h, w in zip(headers[1:], num_w)]
    lines = [" ".join(head_cells)]

    # —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
    sep = "-" * max_name_w + " " + " ".join("-" * w for w in num_w)
    lines.append(sep)

    # —Å—Ç—Ä–æ–∫–∏
    for r in rows:
        name = _pad(r[0], max_name_w)
        nums = [v.rjust(w) for v, w in zip(r[1:], num_w)]
        lines.append(" ".join([name] + nums))

    return _pre_block("\n".join(lines))


# ‚îÄ‚îÄ‚îÄ –û—Ç—á—ë—Ç (—Ç–∞–±–ª–∏—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


def sales_report_text(sku: int, start: str, end: str) -> str:
    # üîí –ñ—ë—Å—Ç–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –æ—Ç—á—ë—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è SKU –∏–∑ WATCH_SKU (–µ—Å–ª–∏ WATCH_SKU –∑–∞–¥–∞–Ω)
    allowed = _allowed_sku_set()
    if allowed and int(sku) not in allowed:
        alias = get_alias_for_sku(sku)
        now = dt.datetime.now().strftime("%d.%m.%Y %H:%M")
        return (
            f"‚õîÔ∏è SKU {sku} ‚Äî <b>{html.escape(alias)}</b> –Ω–µ –Ω–∞–±–ª—é–¥–∞–µ—Ç—Å—è (–Ω–µ –≤—Ö–æ–¥–∏—Ç –≤ WATCH_SKU).\n"
            f"–û–±–Ω–æ–≤–ª–µ–Ω–æ {now}\n"
            "–î–æ–±–∞–≤—å—Ç–µ SKU –≤ WATCH_SKU –≤ .env –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–æ–ø—ã—Ç–∫—É."
        )

    alias = get_alias_for_sku(sku)
    now = dt.datetime.now().strftime("%d.%m.%Y %H:%M")
    head = f"üìÑ –Æ–Ω–∏—Ç-–æ—Ç—á—ë—Ç –ø–æ SKU {sku} ‚Äî <b>{html.escape(alias)}</b>\n" f"üìÖ {
            _parse_date(start).strftime('%d.%m.%Y')}‚Äì{
            _parse_date(end).strftime('%d.%m.%Y')} ‚Ä¢ –û–±–Ω–æ–≤–ª–µ–Ω–æ {now}\n"

    clusters = _collect_clusters_for_sku(sku, start, end)

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    total_o = total_c = total_r = 0

    def _sort_key(kv: Tuple[str, Dict[str, int]]):
        cl, agg = kv
        return (1 if cl == UNKNOWN_CLUSTER else 0, -int(agg["ordered"]), str(cl))

    rows: List[List[str]] = []
    unknown_present = False
    max_name_len = 0

    for cl, agg in sorted(clusters.items(), key=_sort_key):
        if cl == UNKNOWN_CLUSTER:
            unknown_present = True
        o, c, r = int(agg["ordered"]), int(agg["cancelled"]), int(agg["returned"])
        net = o - c - r
        total_o += o
        total_c += c
        total_r += r

        name = _shorten_cluster(cl)
        max_name_len = max(max_name_len, len(name))
        rows.append([name, _fmt_int(o), _fmt_int(c), _fmt_int(r), _fmt_int(net)])

    # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
    if not rows:
        table_block = _pre_block("‚Äî –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º –Ω–µ—Ç ‚Äî")
    else:
        headers = ["–ö–ª–∞—Å—Ç–µ—Ä", "–ó–∞–∫–∞–∑", "–û—Ç–º", "–í–æ–∑–≤—Ä", "–ò—Ç–æ–≥"]
        name_w = min(max(max_name_len, len(headers[0])), MAX_CLUSTER_NAME_W)
        table_block = _pre_table(headers, rows, name_w)

    # –ò–¢–û–ì–û
    net_total = total_o - total_c - total_r
    total_block = "<b>üìä –ò–¢–û–ì–û</b>\n" + _pre_kv(
        [
            ("–ó–∞–∫–∞–∑–∞–Ω–æ", _fmt_int(total_o)),
            ("–û—Ç–º–µ–Ω–µ–Ω–æ", _fmt_int(total_c)),
            ("–í–æ–∑–≤—Ä–∞—â–µ–Ω–æ", _fmt_int(total_r)),
            ("–ò—Ç–æ–≥", _fmt_int(net_total)),
        ]
    )

    # ‚Äî –°–≤–µ—Ä–∫–∞ —Å –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π OZON ‚Äî (–≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π KV‚Äë–±–ª–æ–∫)
    a = _fetch_analytics_totals(sku, start, end)
    d_ord = a["ordered_units"] - total_o
    d_cnc = a["cancellations"] - total_c
    d_ret = a["returns"] - total_r

    check_pairs = [
        ("–ó–∞–∫–∞–∑–∞–Ω–æ (OZON)", _fmt_int(a["ordered_units"])),
        ("–û—Ç–º–µ–Ω–µ–Ω–æ (OZON)", _fmt_int(a["cancellations"])),
        ("–í–æ–∑–≤—Ä–∞—â–µ–Ω–æ (OZON)", _fmt_int(a["returns"])),
    ]
    if any([d_ord, d_cnc, d_ret]):
        diffs = []
        if d_ord:
            diffs.append(f"–∑–∞–∫–∞–∑—ã {d_ord:+}")
        if d_cnc:
            diffs.append(f"–æ—Ç–º–µ–Ω—ã {d_cnc:+}")
        if d_ret:
            diffs.append(f"–≤–æ–∑–≤—Ä–∞—Ç—ã {d_ret:+}")
        check_pairs.append(("–†–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ", "; ".join(diffs)))
    else:
        check_pairs.append(("–°–≤–µ—Ä–∫–∞", "‚úÖ –°–æ–≤–ø–∞–¥–∞–µ—Ç —Å –ª–∏—Å—Ç–∏–Ω–≥–∞–º–∏ FBO/FBS"))

    check_block = "<b>üßÆ –°–≤–µ—Ä–∫–∞ —Å –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π OZON</b>\n" + _pre_kv(check_pairs)

    legend = "üì¶ ‚Äî –∑–∞–∫–∞–∑–∞–Ω–æ ‚Ä¢ ‚ùå ‚Äî –æ—Ç–º–µ–Ω–µ–Ω–æ ‚Ä¢ ‚Ü©Ô∏è ‚Äî –≤–æ–∑–≤—Ä–∞—â–µ–Ω–æ ‚Ä¢ ‚öñÔ∏è ‚Äî –∏—Ç–æ–≥"
    note = (
        "\n‚ÑπÔ∏è ¬´–ë–µ–∑ –∫–ª–∞—Å—Ç–µ—Ä–∞¬ª ‚Äî –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∫–ª–∞—Å—Ç–µ—Ä "
        "(–Ω–µ—Ç —Å–≤—è–∑–∏ warehouse_id ‚Üí –∫–ª–∞—Å—Ç–µ—Ä)."
    )

    parts = [head, table_block, "", total_block, "", check_block, legend]
    if unknown_present:
        parts.append(note)
    return "\n".join(parts)
