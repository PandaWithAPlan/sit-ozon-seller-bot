from __future__ import annotations
from modules_common.paths import ensure_dirs, CACHE_SALES

import os
import json
import time
import asyncio
import datetime as dt
from typing import Dict, List, Tuple, Any, Optional

import aiohttp
from dotenv import load_dotenv

# ‚îÄ‚îÄ –±–∞–∑–æ–≤—ã–µ –ø—É—Ç–∏ / env –ø–æ –¢–ó 5.1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
load_dotenv(os.path.join(ROOT_DIR, ".env"))

ensure_dirs()

OZON_CLIENT_ID = os.getenv("OZON_CLIENT_ID", "")
OZON_API_KEY = os.getenv("OZON_API_KEY", "")
OZON_COMPANY_ID = os.getenv("OZON_COMPANY_ID", "")
PRODUCTS_MODE = (os.getenv("PRODUCTS_MODE", "SKU") or "SKU").upper()

# —Ñ–∏–ª—å—Ç—Ä—ã (–∫–∞–∫ —Å—Ç—Ä–æ–∫–∏!)
WATCH_SKU: List[str] = [
    s.strip() for s in (os.getenv("WATCH_SKU", "") or "").split(",") if s.strip()
]
WATCH_OFFERS: List[str] = [
    s.strip() for s in (os.getenv("WATCH_OFFERS", "") or "").split(",") if s.strip()
]

# –¥—Ä–æ—Å—Å–µ–ª—å —Ç—Ä–∞—Ñ–∏–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
TRAFFIC_MIN_INTERVAL = float(os.getenv("TRAFFIC_MIN_INTERVAL", "65"))
_LAST_TRAFFIC_CALL = 0.0

# –≤–Ω–µ—à–Ω–∏–π –≤–∏–¥


def _now_stamp() -> str:
    return dt.datetime.now().strftime("%d.%m.%Y %H:%M")


def _fmt_pct(x: float) -> str:
    try:
        return f"{float(x):.2f}%"
    except Exception:
        return "0.00%"


# ‚îÄ‚îÄ —Ä–µ—é–∑ —Ö–µ–ª–ø–µ—Ä–æ–≤ –∏–∑ sales_facts_store: –∞–ª–∏–∞—Å—ã, –ø–æ—Ä—è–¥–æ–∫, –¥–æ–ø—É—Å—Ç–∏–º—ã–µ SKU ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
try:
    from modules_sales.sales_facts_store import (
        get_alias_for_sku,
        _watch_skus_order_list as _order_list,  # type: ignore
        _allowed_sku_set as _allowed_set,  # type: ignore
    )
except Exception:
    # –§–æ–ª–±—ç–∫, –µ—Å–ª–∏ –ø—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
    def get_alias_for_sku(sku: int) -> str | None:
        return None

    def _order_list() -> List[int]:
        out: List[int] = []
        seen: set[int] = set()
        raw = (os.getenv("WATCH_SKU", "") or "").replace("\n", ",")
        for tok in raw.split(","):
            tok = tok.strip()
            if not tok:
                continue
            left = tok.split(":", 1)[0].strip()
            if not left.isdigit():
                continue
            v = int(left)
            if v not in seen:
                seen.add(v)
                out.append(v)
        return out

    def _allowed_set() -> set[int]:
        st: set[int] = set()
        for s in (os.getenv("WATCH_SKU", "") or "").split(","):
            s = s.strip()
            if ":" in s:
                s = s.split(":", 1)[0].strip()
            if s.isdigit():
                st.add(int(s))
        return st


# -------- HTTP
OZON_API_URL = "https://api-seller.ozon.ru/v1/analytics/data"


def _headers() -> Dict[str, str]:
    return {
        "Client-Id": OZON_CLIENT_ID,
        "Api-Key": OZON_API_KEY,
        "Content-Type": "application/json",
    }


# -------- –∫—ç—à (–¥–ª—è –æ—Ñ—Ñ–ª–∞–π–Ω-—Ñ–æ–ª–±—ç–∫–∞) ‚Üí –≤ data/cache/sales/
TRAFFIC_CACHE_FILE = os.path.join(CACHE_SALES, "traffic_cache.json")


def _read_cache_sync() -> dict:
    if not os.path.exists(TRAFFIC_CACHE_FILE):
        return {}
    try:
        with open(TRAFFIC_CACHE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {}


async def _read_cache() -> dict:
    return await asyncio.to_thread(_read_cache_sync)


def _write_cache_sync(payload: dict) -> None:
    try:
        with open(TRAFFIC_CACHE_FILE, "w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=False)
    except Exception:
        pass


async def _write_cache(payload: dict) -> None:
    await asyncio.to_thread(_write_cache_sync, payload)


# -------- –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ payload
# –Ω—É–∂–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Ç—Ä–∞—Ñ–∏–∫–∞:
# - hits_view_pdp: –ø–æ–∫–∞–∑—ã –Ω–∞ –∫–∞—Ä—Ç–æ—á–∫–µ
# - hits_tocart_pdp: –∫–ª–∏–∫–∏ "–≤ –∫–æ—Ä–∑–∏–Ω—É" —Å –∫–∞—Ä—Ç–æ—á–∫–∏
# - session_view_pdp: —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–∏ –∫–∞—Ä—Ç–æ—á–∫–∏
# - ordered_units: –∑–∞–∫–∞–∑–∞–Ω–Ω—ã–µ —é–Ω–∏—Ç—ã (–¥–ª—è CVR –∫ –ø–æ–∫—É–ø–∫–µ)
TRAFFIC_METRICS = ["hits_view_pdp", "hits_tocart_pdp", "session_view_pdp", "ordered_units"]


def _payload_traffic(date_from: str, date_to: str) -> Dict[str, Any]:
    """–ì–æ—Ç–æ–≤–∏–º payload –¥–ª—è sku+day. –í–ê–ñ–ù–û: filters.value —Å—Ç—Ä–æ–∫–æ–π."""
    p: Dict[str, Any] = {
        "date_from": date_from,
        "date_to": date_to,
        "metrics": TRAFFIC_METRICS,
        "dimension": ["sku", "day"],  # ‚Üê —Ç–æ–ª—å–∫–æ sku+day
        "limit": 1000,
        "offset": 0,
    }
    if OZON_COMPANY_ID:
        p["company_id"] = OZON_COMPANY_ID

    if PRODUCTS_MODE == "SKU" and WATCH_SKU:
        only_digits: List[str] = []
        for s in WATCH_SKU:
            s = s.strip()
            if ":" in s:
                s = s.split(":", 1)[0].strip()
            if s.isdigit():
                only_digits.append(s)
        if only_digits:
            p["filters"] = [
                {
                    "key": "sku",
                    "value": ",".join(only_digits),  # ‚Üê —Å—Ç—Ä–æ–∫–∞ "123,456"
                    "operator": "IN",
                }
            ]
    elif PRODUCTS_MODE == "OFFER" and WATCH_OFFERS:
        p["filters"] = [
            {"key": "offer_id", "value": ",".join(WATCH_OFFERS), "operator": "IN"}  # ‚Üê —Å—Ç—Ä–æ–∫–∞
        ]
    return p


async def _try_fetch(
    payload: dict, tag: str, session: Optional[aiohttp.ClientSession] = None
) -> dict | None:
    """–° —É—á—ë—Ç–æ–º –¥—Ä–æ—Å—Å–µ–ª—è –∏ –º—è–≥–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ 429/403/400."""
    global _LAST_TRAFFIC_CALL

    # –Ω–µ —á–∞—â–µ, —á–µ–º —Ä–∞–∑ –≤ TRAFFIC_MIN_INTERVAL —Å–µ–∫—É–Ω–¥
    if time.time() - _LAST_TRAFFIC_CALL < TRAFFIC_MIN_INTERVAL:
        return None

    try:
        timeout = aiohttp.ClientTimeout(total=30)
        if session:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é —Å–µ—Å—Å–∏—é
            async with session.post(
                OZON_API_URL, headers=_headers(), json=payload, timeout=timeout
            ) as r:
                return await _handle_response(r, tag)
        else:
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é —Å–µ—Å—Å–∏—é (fallback)
            async with aiohttp.ClientSession() as tmp_session:
                async with tmp_session.post(
                    OZON_API_URL, headers=_headers(), json=payload, timeout=timeout
                ) as r:
                    return await _handle_response(r, tag)
    except Exception as e:
        print(f"[traffic] HTTP fetch failed ({tag}): {e}")
        return None


async def _handle_response(r: aiohttp.ClientResponse, tag: str) -> dict | None:
    global _LAST_TRAFFIC_CALL
    if r.status in (429, 403, 400):
        text = await r.text()
        body = text[:240].replace("\n", " ")
        print(f"[traffic] HTTP fetch failed ({tag}): {r.status} {body}")
        return None
    r.raise_for_status()
    _LAST_TRAFFIC_CALL = time.time()
    return await r.json()


async def _fetch_traffic(date_from: str, date_to: str) -> dict | None:
    """–ü—Ä–æ–±—É–µ–º: 1) —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏  2) –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–æ–≤ (–ø–æ—Ç–æ–º –≤—Ä—É—á–Ω—É—é –æ—Ç—Ñ–∏–ª—å—Ç—Ä—É–µ–º)."""
    async with aiohttp.ClientSession() as session:
        # —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
        p = _payload_traffic(date_from, date_to)
        js = await _try_fetch(p, "sku+day", session=session)
        if js and (js.get("result") or js.get("data")):
            return js

        # –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–æ–≤
        p.pop("filters", None)
        js = await _try_fetch(p, "sku+day/nofilter", session=session)
        if js and (js.get("result") or js.get("data")):
            return js

    return None


# -------- —Å–±–æ—Ä –º–∞—Ç—Ä–∏—Ü—ã: {sku: {date: (views, clicks, sessions, units)}}


async def _collect_traffic_matrix(
    days: int,
) -> Dict[int, Dict[dt.date, Tuple[float, float, float, float]]]:
    end = dt.date.today()
    start = end - dt.timedelta(days=days - 1)
    date_from = start.strftime("%Y-%m-%d")
    date_to = end.strftime("%Y-%m-%d")

    allowed = _allowed_set()

    js = await _fetch_traffic(date_from, date_to)
    matrix: Dict[int, Dict[dt.date, Tuple[float, float, float, float]]] = {}

    def _push(sku: int, d: dt.date, v: float, c: float, s: float, u: float) -> None:
        """–î–æ–±–∞–≤–∏—Ç—å —Å—Ç—Ä–æ–∫—É –≤ –º–∞—Ç—Ä–∏—Ü—É —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ allowed."""
        if allowed and sku not in allowed:
            return
        pv, pc, ps, pu = matrix.get(sku, {}).get(d, (0.0, 0.0, 0.0, 0.0))
        matrix.setdefault(sku, {})[d] = (pv + v, pc + c, ps + s, pu + u)

    if not js:
        # –æ—Ñ—Ñ–ª–∞–π–Ω –∏–∑ –∫—ç—à–∞ (—Å—Ç—Ä–æ–≥–æ –ø–æ allowed)
        cached = await _read_cache()
        for sku_s, rows in (cached.get("rows") or {}).items():
            try:
                sku = int(sku_s)
            except Exception:
                continue
            if allowed and sku not in allowed:
                continue
            for r in rows:
                try:
                    d = dt.datetime.strptime(r["date"], "%Y-%m-%d").date()
                except Exception:
                    continue
                if not (start <= d <= end):
                    continue
                v = float(r.get("views", 0.0))
                c = float(r.get("clicks", 0.0))
                s = float(r.get("sessions", 0.0))
                u = float(r.get("units", 0.0))
                _push(sku, d, v, c, s, u)
        return matrix

    data = js.get("result", {}).get("data", []) or js.get("data", []) or []
    to_cache: Dict[str, List[dict]] = {}

    for row in data:
        # sku
        sku_raw = (
            row.get("sku")
            or row.get("product_id")
            or (row.get("dimension") or {}).get("sku")
            or (row.get("dimensions", [{}])[0].get("id") if row.get("dimensions") else None)
        )
        try:
            sku = int(sku_raw)
        except Exception:
            continue

        # –¥–∞—Ç–∞
        d_str = (
            row.get("date")
            or (row.get("dimension") or {}).get("date")
            or row.get("day")
            or (row.get("dimension") or {}).get("day")
        )
        if not d_str and isinstance(row.get("dimensions"), list):
            for dim in row["dimensions"]:
                di = (dim or {}).get("id")
                if isinstance(di, str):
                    try:
                        dt.date.fromisoformat(di)
                        d_str = di
                        break
                    except Exception:
                        pass
        if not d_str:
            continue

        try:
            d = dt.date.fromisoformat(d_str)
        except Exception:
            continue

        # –º–µ—Ç—Ä–∏–∫–∏
        metrics = row.get("metrics") or row.get("value") or {}
        if isinstance(metrics, list):
            # hits_view_pdp, hits_tocart_pdp, session_view_pdp, ordered_units
            v = float(metrics[0] if len(metrics) > 0 else 0.0)
            c = float(metrics[1] if len(metrics) > 1 else 0.0)
            s = float(metrics[2] if len(metrics) > 2 else 0.0)
            u = float(metrics[3] if len(metrics) > 3 else 0.0)
        else:
            v = float(metrics.get("hits_view_pdp", 0.0))
            c = float(metrics.get("hits_tocart_pdp", 0.0))
            s = float(metrics.get("session_view_pdp", 0.0))
            u = float(metrics.get("ordered_units", 0.0))

        _push(sku, d, v, c, s, u)

        # –∫—ç—à–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞–±–ª—é–¥–∞–µ–º—ã–µ (—É–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞)
        if not allowed or sku in allowed:
            to_cache.setdefault(str(sku), []).append(
                {"date": d.strftime("%Y-%m-%d"), "views": v, "clicks": c, "sessions": s, "units": u}
            )

    await _write_cache({"rows": to_cache})
    return matrix


# -------- –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ –ø–µ—Ä–∏–æ–¥—É


def _aggregate_for_period(
    matrix: Dict[int, Dict[dt.date, Tuple[float, float, float, float]]], period_days: int
) -> Dict[int, Tuple[float, float, float, float]]:
    days = int(period_days)
    days = 1 if days == 0 else days
    today = dt.date.today()
    last_date = max((d for m in matrix.values() for d in m.keys()), default=today)
    if period_days == 0:
        start = last_date
        end = last_date
    elif period_days == 1:
        end = last_date - dt.timedelta(days=1)
        start = end
    else:
        end = last_date
        start = end - dt.timedelta(days=days - 1)

    result: Dict[int, Tuple[float, float, float, float]] = {}
    allowed = _allowed_set()
    for sku, dmap in matrix.items():
        if allowed and sku not in allowed:
            continue
        v = c = s = u = 0.0
        for d, (vv, cc, ss, uu) in dmap.items():
            if start <= d <= end:
                v += vv
                c += cc
                s += ss
                u += uu
        if v > 0 or c > 0 or s > 0 or u > 0:
            result[sku] = (v, c, s, u)
    return result


# -------- –ø—É–±–ª–∏—á–Ω—ã–π —Ç–µ–∫—Å—Ç


def _period_label(days: int) -> str:
    if days == 0:
        return "–°–µ–≥–æ–¥–Ω—è"
    if days == 1:
        return "–í—á–µ—Ä–∞"
    return f"–ü–æ—Å–ª–µ–¥–Ω–∏–µ {days} –¥–Ω–µ–π"


async def traffic_text(period_days: int, metric: str = "ctr") -> str:
    """metric: 'ctr' | 'cvr'"""
    metric = (metric or "ctr").lower()
    head_metric = {"ctr": "–ö–õ–ò–ö–ê–ë–ï–õ–¨–ù–û–°–¢–¨", "cvr": "–ö–û–ù–í–ï–†–°–ò–Ø"}.get(metric, "–ö–õ–ò–ö–ê–ë–ï–õ–¨–ù–û–°–¢–¨")

    # –±—É—Ñ–µ—Ä 30 –¥–Ω–µ–π, —á—Ç–æ–±—ã –ª—é–±—ã–µ –ø–µ—Ä–∏–æ–¥—ã —Å—á–∏—Ç–∞–ª–∏—Å—å –∏–∑ –æ–¥–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã
    matrix = await _collect_traffic_matrix(max(int(period_days) if period_days else 1, 30))
    agg = _aggregate_for_period(matrix, int(period_days))

    lines: List[str] = []
    order = _order_list()  # ‚Üê –ø–æ—Ä—è–¥–æ–∫ –∏–∑ WATCH_SKU

    tot_ctr_num = tot_ctr_den = 0.0
    tot_cvr_num = tot_cvr_den = 0.0

    for sku in order:
        if sku not in agg:
            continue
        alias = get_alias_for_sku(sku)
        if not alias:
            continue
        views, clicks, sessions, units = agg[sku]

        # CTR = –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –∫–æ—Ä–∑–∏–Ω—É / –ø–æ–∫–∞–∑—ã PDP
        ctr = (clicks / views * 100.0) if views > 0 else 0.0
        # CVR = –∑–∞–∫–∞–∑–∞–Ω–Ω—ã–µ —é–Ω–∏—Ç—ã / —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–∏ PDP
        cvr = (units / sessions * 100.0) if sessions > 0 else 0.0

        if metric == "ctr":
            lines.append(f"üîπ {alias} ‚Äî {_fmt_pct(ctr)}")
            tot_ctr_num += clicks
            tot_ctr_den += views
        else:
            lines.append(f"üîπ {alias} ‚Äî {_fmt_pct(cvr)}")
            tot_cvr_num += units
            tot_cvr_den += sessions

    if not lines:
        lines = ["‚Äî –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç ‚Äî"]

    if metric == "ctr":
        total = (tot_ctr_num / tot_ctr_den * 100.0) if tot_ctr_den > 0 else 0.0
        total_line = f"üìä –°—Ä–µ–¥–Ω–∏–π CTR: {_fmt_pct(total)}"
    else:
        total = (tot_cvr_num / tot_cvr_den * 100.0) if tot_cvr_den > 0 else 0.0
        total_line = f"üìä –°—Ä–µ–¥–Ω—è—è –∫–æ–Ω–≤–µ—Ä—Å–∏—è: {_fmt_pct(total)}"

    header = (
        f"üìÑ –¢—Ä–∞—Ñ–∏–∫ ‚Äî –§–∞–∫—Ç ({head_metric})\n"
        f"üìÖ {_now_stamp()} ‚Ä¢ {_period_label(int(period_days))}\n"
    )

    return "\n".join([header, *lines, "", total_line])
