# modules_sales/sales_facts_store.py
from __future__ import annotations
from modules_common.paths import ensure_dirs, DATA_DIR, CACHE_SALES
from modules_common.cache_manager import SalesCache
from config_package.constants import TrafficMetric
from config_package import settings
import logging
import os
import json
import time
import datetime as dt
import asyncio
from typing import Dict, List, Tuple, Any, Optional

import aiohttp
from config_package import safe_read_json, safe_write_json

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
log = logging.getLogger("seller-bot.sales_facts_store")

# –ï–¥–∏–Ω—ã–µ –ø—É—Ç–∏
ensure_dirs()

# –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–∏–ø–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
OZON_CLIENT_ID: str = settings.ozon_client_id
OZON_API_KEY: str = settings.ozon_api_key
OZON_COMPANY_ID: str = settings.ozon_company_id
PRODUCTS_MODE: str = settings.products_mode

# –î—Ä–æ—Å—Å–µ–ª—å API: –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É —É–¥–∞—á–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ (—Å–µ–∫—É–Ω–¥—ã)
MIN_INTERVAL: float = 65.0
_LAST_API_CALL: float = 0.0  # timestamp –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —É–¥–∞—á–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞

OZON_API_URL: str = settings.ozon_api_url

# ---------- –∞–ª–∏–∞—Å—ã –∏–∑ .env ----------
_ALIAS_CACHE: Dict[int, str] = {}


def _watch_skus_order_list() -> List[int]:
    """
    –ß–∏—Ç–∞–µ—Ç WATCH_SKU, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç 'sku' –∏ 'sku:alias'.
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫, —É–±–∏—Ä–∞–µ—Ç –¥—É–±–ª–∏.

    Returns:
        –°–ø–∏—Å–æ–∫ SKU –≤ –ø–æ—Ä—è–¥–∫–µ WATCH_SKU
    """
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º settings.parsed_watch_sku.
    # –≠—Ç–∞ –ø—Ä–æ–ø–µ—Ä—Ç–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É–∂–µ int —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö SKU –≤ –ø–æ—Ä—è–¥–∫–µ —É–∫–∞–∑–∞–Ω–∏—è.
    return settings.parsed_watch_sku


def _allowed_sku_set() -> set[int]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö SKU.

    Returns:
        –ú–Ω–æ–∂–µ—Å—Ç–≤–æ SKU –∏–∑ WATCH_SKU
    """
    return set(settings.parsed_watch_sku)


def _parse_alias_pairs(raw: str) -> Dict[int, str]:
    """
    –ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞:
        "ALIAS_1831342831=stand_ABS_black,1831342958=stand_ABS_white,..."
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∫–ª—é—á–∏ –∫–∞–∫ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º ALIAS_, —Ç–∞–∫ –∏ –±–µ–∑ –Ω–µ–≥–æ.

    Args:
        raw: –°—Ç—Ä–æ–∫–∞ —Å –ø–∞—Ä–∞–º–∏ –∞–ª–∏–∞—Å–æ–≤

    Returns:
        –°–ª–æ–≤–∞—Ä—å {sku: alias}
    """
    res: Dict[int, str] = {}
    if not raw:
        return res
    text = raw.replace("\n", ",")
    for token in text.split(","):
        token = token.strip()
        if not token or "=" not in token:
            continue
        k, v = token.split("=", 1)
        key = (k or "").strip()
        val = (v or "").strip()
        if not key or not val:
            continue
        if key.upper().startswith("ALIAS_"):
            key = key[6:]
        key = key.strip()
        if not key.isdigit():
            continue
        try:
            sku = int(key)
            res[sku] = val
        except Exception:
            continue
    return res
    text = raw.replace("\n", ",")
    for token in text.split(","):
        token = token.strip()
        if not token or "=" not in token:
            continue
        k, v = token.split("=", 1)
        key = (k or "").strip()
        val = (v or "").strip()
        if not key or not val:
            continue
        if key.upper().startswith("ALIAS_"):
            key = key[6:]
        key = key.strip()
        if not key.isdigit():
            continue
        try:
            sku = int(key)
            res[sku] = val
        except Exception:
            continue
    return res


def _apply_aliases_from_watch_sku() -> Dict[int, str]:
    """
    –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ—Ç –∞–ª–∏–∞—Å—ã –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞ WATCH_SKU="sku:alias,...",
    –µ—Å–ª–∏ —Ç–∞–∫–∏–µ –≤—Å—Ç—Ä–µ—Ç—è—Ç—Å—è; –Ω–µ –ø–µ—Ä–µ—Ç–∏—Ä–∞–µ—Ç —è–≤–Ω—ã–µ ALIAS_*.

    Returns:
        –°–ª–æ–≤–∞—Ä—å {sku: alias}
    """
    res: Dict[int, str] = {}
    raw = (settings.watch_sku or "").replace("\n", ",").replace(" ", ",")
    for token in raw.split(","):
        token = token.strip()
        if ":" not in token:
            continue
        left, alias = token.split(":", 1)
        left = left.strip()
        alias = alias.strip()
        if not left.isdigit() or not alias:
            continue
        try:
            res[int(left)] = alias
        except Exception:
            continue
    return res


def _build_alias_cache() -> None:
    """
    –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∞–ª–∏–∞—Å–æ–≤ (–ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É ‚Äî –ø–æ–∑–∂–µ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞–µ—Ç —Ä–∞–Ω–µ–µ):
        1) ALIAS=<pairs>  (–µ–¥–∏–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
        2) ALIAS_<SKU>=<alias> (–ø–æ—Å—Ç—Ä–æ—á–Ω–æ)
        3) WATCH_SKU="sku:alias" (–¥–æ–ø–æ–ª–Ω—è–µ–º, –µ—Å–ª–∏ –∞–ª–∏–∞—Å–∞ –µ—â—ë –Ω–µ—Ç)
    """
    _ALIAS_CACHE.clear()

    # 1) ALIAS="ALIAS_183=xxx,1831342958=yyy,..."
    _ALIAS_CACHE.update(_parse_alias_pairs(os.getenv("ALIAS", "") or ""))

    # 2) –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π —Ñ–æ—Ä–º–∞—Ç –ø–æ—Å—Ç—Ä–æ—á–Ω–æ
    for k, v in os.environ.items():
        if not k.startswith("ALIAS_"):
            continue
        try:
            sku = int(k.split("_", 1)[1])
            _ALIAS_CACHE[sku] = (v or "").strip()
        except Exception:
            continue

    # 3) –ê–ª–∏–∞—Å—ã –ø—Ä—è–º–æ –≤ WATCH_SKU (sku:alias) ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º, –µ—Å–ª–∏ –Ω–µ—Ç
    for sku, alias in _apply_aliases_from_watch_sku().items():
        _ALIAS_CACHE.setdefault(sku, alias)

    print(f"[sales_facts_store] alias cache built for {len(_ALIAS_CACHE)} sku")


def get_alias_for_sku(sku: int) -> str | None:
    if not _ALIAS_CACHE:
        _build_alias_cache()
    return _ALIAS_CACHE.get(int(sku))

# ---------- —É—Ç–∏–ª–∏—Ç—ã ----------


def _headers() -> Dict[str, str]:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è API –∑–∞–ø—Ä–æ—Å–æ–≤.

    Returns:
        –°–ª–æ–≤–∞—Ä—å –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ HTTP
    """
    return {
        "Client-Id": OZON_CLIENT_ID,
        "Api-Key": OZON_API_KEY,
        "Content-Type": "application/json",
    }


def _now_stamp() -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É/–≤—Ä–µ–º—è –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.

    Returns:
        –°—Ç—Ä–æ–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "–î–î.–ú–ú.–ì–ì–ì–ì –ß–ß:–ú–ú"
    """
    # Note: using Latin M for minutes
    return dt.datetime.now().strftime("%d.%m.%Y %H:%M")


def _fmt_money(value: float) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –¥–µ–Ω–µ–∂–Ω—É—é —Å—É–º–º—É —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏.

    Args:
        value: –ó–Ω–∞—á–µ–Ω–∏–µ –≤ —Ä—É–±–ª—è—Ö

    Returns:
        –°—Ç—Ä–æ–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "1 234 ‚ÇΩ"
    """
    return f"{int(round(value)):,}".replace(",", " ") + " ‚ÇΩ"


def _fmt_units(value: float) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à—Ç—É–∫.

    Args:
        value: –ó–Ω–∞—á–µ–Ω–∏–µ –≤ —à—Ç—É–∫–∞—Ö

    Returns:
        –°—Ç—Ä–æ–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "123 —à—Ç"
    """
    return f"{int(round(value))} —à—Ç"


# ---------- –∫—ç—à (–ø–µ—Ä–µ–Ω–æ—Å –≤ data/cache/sales) ----------

def _read_cache() -> dict:
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–æ —á–∏—Ç–∞–µ—Ç –∫—ç—à —Å –¥–∏—Å–∫–∞ —á–µ—Ä–µ–∑ CacheManager.
    """
    return SalesCache.get_facts_cache_manager().get_data()


def _write_cache(payload: dict) -> None:
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–æ –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∫—ç—à –Ω–∞ –¥–∏—Å–∫ —á–µ—Ä–µ–∑ CacheManager.
    """
    SalesCache.get_facts_cache_manager().set_data(payload)

# ---------- –∑–∞–ø—Ä–æ—Å —Ñ–∞–∫—Ç–æ–≤ ----------


def _payload_base(date_from: str, date_to: str) -> Dict[str, Any]:
    """
    –ë–∞–∑–æ–≤—ã–π payload –¥–ª—è /v1/analytics/data.
    –í–ù–ò–ú–ê–ù–ò–ï: limit <= 1000 (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ API).
    –í—Å–µ–≥–¥–∞ –ø—Ä–æ—Å–∏–º —Ä–∞–∑—Ä–µ–∑ –ø–æ –¥–Ω—è–º, —á—Ç–æ–±—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–∏–æ–¥—ã.

    Args:
        date_from: –î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "YYYY-MM-DD"
        date_to: –î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ "YYYY-MM-DD"

    Returns:
        –°–ª–æ–≤–∞—Ä—å payload –¥–ª—è API –∑–∞–ø—Ä–æ—Å–∞
    """
    payload: Dict[str, Any] = {
        "date_from": date_from,
        "date_to": date_to,
        "dimension": ["sku", "day"],       # –≤—Å–µ–≥–¥–∞ sku+day
        "limit": 1000,
        "offset": 0,
    }
    if OZON_COMPANY_ID:
        payload["company_id"] = OZON_COMPANY_ID

    # üîí –ñ—ë—Å—Ç–∫–æ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤—ã–±–æ—Ä–∫—É –Ω–∞–±–ª—é–¥–∞–µ–º—ã–º–∏ SKU/offer
    if PRODUCTS_MODE == "SKU":
        # settings.parsed_watch_sku - —ç—Ç–æ List[int]
        only_digits = [str(s) for s in settings.parsed_watch_sku]
        if only_digits:
            payload["filters"] = [{
                "key": "sku",
                "value": ",".join(only_digits),
                "operator": "IN"
            }]
    elif PRODUCTS_MODE == "OFFER":
        offers = settings.parsed_watch_offers
        if offers:
            payload["filters"] = [{
                "key": "offer_id",
                "value": ",".join(offers),
                "operator": "IN"
            }]

    return payload


async def _try_fetch(payload: dict) -> dict | None:
    """
    –î—Ä–æ—Å—Å–µ–ª–∏—Ä—É–µ–º –æ–±—Ä–∞—â–µ–Ω–∏—è –∏ –º—è–≥–∫–æ –æ–±—Ö–æ–¥–∏–º 429/–ª–∏–º–∏—Ç—ã.
    –ï—Å–ª–∏ —Å–ª–∏—à–∫–æ–º —á–∞—Å—Ç–æ ‚Äî –≤–µ—Ä–Ω—ë–º None (–ø—É—Å—Ç—å —Å—Ä–∞–±–æ—Ç–∞–µ—Ç –∫—ç—à).

    Args:
        payload: Payload –¥–ª—è API –∑–∞–ø—Ä–æ—Å–∞

    Returns:
        JSON-–æ—Ç–≤–µ—Ç –æ—Ç API –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ/–ª–∏–º–∏—Ç–µ
    """
    global _LAST_API_CALL

    since = time.time() - _LAST_API_CALL
    if since < MIN_INTERVAL:
        return None

    try:
        timeout = aiohttp.ClientTimeout(connect=5, total=30)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.post(OZON_API_URL, headers=_headers(), json=payload) as r:
                if r.status in (429, 403):
                    try:
                        text = await r.text()
                        log.warning(
                            f"API rate limited/forbidden (status {r.status}): {text[:180]}"
                        )
                    except Exception:
                        log.warning(f"API rate limited/forbidden (status {r.status})")
                    return None

                r.raise_for_status()
                _LAST_API_CALL = time.time()
                result = await r.json()
                log.info("Successfully fetched sales facts from API")
                return result

    except asyncio.TimeoutError as e:
        log.warning(f"API timeout when fetching sales facts: {e}")
        return None
    except aiohttp.ClientError as e:
        log.warning(f"API connection error when fetching sales facts: {e}")
        return None
    except Exception as e:
        log.critical(f"Unexpected error in _try_fetch: {e}", exc_info=True)
        return None


async def _fetch_matrix(date_from: str,                            date_to: str) -> Dict[int, Dict[dt.date, Tuple[float, float]]]:
    """
    –¢—è–Ω–µ–º –û–î–ù–ò–ú –∑–∞–ø—Ä–æ—Å–æ–º metrics=["ordered_units","revenue"] –∏ —Å–æ–±–∏—Ä–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É sku+day.
    –¢–∞–∫ –º—ã –Ω–µ —É–ø–∏—Ä–∞–µ–º—Å—è –≤ –¥—Ä–æ—Å—Å–µ–ª—å –≤—Ç–æ—Ä—ã–º –≤—ã–∑–æ–≤–æ–º –∏ –≤—Å–µ–≥–¥–∞ –ø–æ–ª—É—á–∞–µ–º –≤—ã—Ä—É—á–∫—É.
    
    Args:
        date_from: –î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "YYYY-MM-DD"
        date_to: –î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ "YYYY-MM-DD"
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å {sku: {date: (units, revenue)}}
    """
    payload = _payload_base(date_from, date_to)
    payload["metrics"] = ["ordered_units", "revenue"]

    js = await _try_fetch(payload)
    if not js:
        print("[sales_facts_store] no valid response after attempts")
        return {}

    data = js.get("result", {}).get("data", []) or js.get("data", []) or []
    matrix: Dict[int, Dict[dt.date, Tuple[float, float]]] = {}

    def _extract_one(row: dict) -> tuple[int | None, dt.date | None, float, float]:
        sku_raw = row.get("sku") or row.get("product_id") or (row.get("dimension") or {}).get("sku")
        day_raw = row.get("date") or (row.get("dimension") or {}).get("date") \
            or row.get("day") or (row.get("dimension") or {}).get("day")

        if sku_raw is None or day_raw is None:
            dims = row.get("dimensions")
            if isinstance(dims, list) and len(dims) >= 2:
                sku_raw = sku_raw or (dims[0].get("id") if isinstance(dims[0], dict) else None)
                day_raw = day_raw or (dims[1].get("id") if isinstance(dims[1], dict) else None)

        try:
            sku = int(str(sku_raw))
        except Exception:
            sku = None
        try:
            day = dt.datetime.strptime(str(day_raw), "%Y-%m-%d").date()
        except Exception:
            day = None

        u = r = 0.0
        m = row.get("metrics")
        if isinstance(m, list):
            u = float(m[0]) if len(m) > 0 and m[0] is not None else 0.0
            r = float(m[1]) if len(m) > 1 and m[1] is not None else 0.0
        elif isinstance(m, dict):
            u = float(m.get("ordered_units", 0) or 0)
            r = float(m.get("revenue", 0) or 0)
        else:
            v = row.get("value", {})
            if isinstance(v, dict):
                u = float(v.get("ordered_units", 0) or 0)
                r = float(v.get("revenue", 0) or 0)

        return sku, day, u, r

    for row in data:
        sku, day, u, r = _extract_one(row)
        if sku is None or day is None:
            continue
        pu, pr = matrix.get(sku, {}).get(day, (0.0, 0.0))
        matrix.setdefault(sku, {})[day] = (pu + u, pr + r)

    to_cache: Dict[str, List[dict]] = {}
    for sku, dmap in matrix.items():
        for day, (u, r) in dmap.items():
            to_cache.setdefault(str(sku), []).append({
                "date": day.strftime("%Y-%m-%d"),
                "units": u,
                "revenue": r,
            })
    _write_cache({"rows": to_cache})

    return matrix

# ---------- –∞–≥—Ä–µ–≥–∞—Ç—ã —Ñ–∞–∫—Ç–∞ ----------
def _period_label_fact(days: int) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –ø–æ–¥–ø–∏—Å—å –¥–ª—è –ø–µ—Ä–∏–æ–¥–∞ –≤ –æ—Ç—á—ë—Ç–∞—Ö –ø–æ —Ñ–∞–∫—Ç–∞–º.
    
    Args:
        days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π (0 - —Å–µ–≥–æ–¥–Ω—è, 1 - –≤—á–µ—Ä–∞)
    
    Returns:
        –°—Ç—Ä–æ–∫–∞ —Å —ç–º–æ–¥–∑–∏ –∫–∞–ª–µ–Ω–¥–∞—Ä—è –∏ –ø–µ—Ä–∏–æ–¥–æ–º
    """
    if days == 0:
        return "üìÖ –°–µ–≥–æ–¥–Ω—è:"
    if days == 1:
        return "üìÖ –í—á–µ—Ä–∞:"
    return f"üìÖ –ü–æ—Å–ª–µ–¥–Ω–∏–µ {days} –¥–Ω–µ–π:"

def _matrix_from_cache(start: dt.date,                           end: dt.date) -> Dict[int, Dict[dt.date, Tuple[float, float]]]:
    """
    –ß—Ç–µ–Ω–∏–µ –∫—ç—à–∞ –° –£–ß–Å–¢–û–ú —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ WATCH_SKU, —á—Ç–æ–±—ã ¬´–ª–µ–≤—ã–µ¬ª SKU –Ω–µ –ø–æ–ø–∞–¥–∞–ª–∏ –≤ –æ—Ç—á—ë—Ç—ã.
    
    Args:
        start: –î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ —Ñ–∏–ª—å—Ç—Ä–∞
        end: –î–∞—Ç–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–∞
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å {sku: {date: (units, revenue)}}
    """
    allowed = _allowed_sku_set()
    cached = _read_cache()
    matrix: Dict[int, Dict[dt.date, Tuple[float, float]]] = {}
    for sku_s, rows in (cached.get("rows") or {}).items():
        try:
            sku = int(sku_s)
        except Exception:
            continue
        if allowed and sku not in allowed:
            continue
        for row in rows:
            try:
                d = dt.datetime.strptime(row["date"], "%Y-%m-%d").date()
            except Exception:
                continue
            if not (start <= d <= end):
                continue
            u = float(row.get("units", 0) or 0)
            r = float(row.get("revenue", 0) or 0)
            matrix.setdefault(sku, {})[d] = (u, r)
    return matrix

async def _collect_matrix(days: int) -> Dict[int, Dict[dt.date, Tuple[float, float]]]:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –º–∞—Ç—Ä–∏—Ü—É –ø—Ä–æ–¥–∞–∂ –∑–∞ —É–∫–∞–∑–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π.
    
    Args:
        days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π (–º–∏–Ω–∏–º—É–º 1)
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å {sku: {date: (units, revenue)}}
    """
    end = dt.date.today()
    start = end - dt.timedelta(days=days - 1)
    mx = await _fetch_matrix(start.strftime("%Y-%m-%d"), end.strftime("%Y-%m-%d")) or {}
    if mx:
        return mx
    return _matrix_from_cache(start, end)

async def get_facts_aggregated(period_days: int,                                   force_update: bool = False) -> Dict[int, Tuple[float, float]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç {sku: (units_sum, revenue_sum)} –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.
    –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç ¬´–≤—á–µ—Ä–∞¬ª: –±–µ—Ä—ë–º –∏–º–µ–Ω–Ω–æ –≤—á–µ—Ä–∞—à–Ω—é—é –¥–∞—Ç—É –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π TZ.
    –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º, —á—Ç–æ –≤ –≤—ã–¥–∞—á–µ —Ç–æ–ª—å–∫–æ SKU –∏–∑ WATCH_SKU.
    
    Args:
        period_days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π (0 - —Å–µ–≥–æ–¥–Ω—è, 1 - –≤—á–µ—Ä–∞, >1 - –ø–µ—Ä–∏–æ–¥)
        force_update: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–µ–∑ –∫—ç—à–∞
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å {sku: (units_sum, revenue_sum)}
    """
    days = max(1, int(period_days))
    matrix = await _collect_matrix(max(days, 30))

    if not matrix:
        return {}

    all_days = [d for m in matrix.values() for d in m.keys()]
    if not all_days:
        return {}
    last_available = max(all_days)

    if period_days == 0:   # —Å–µ–≥–æ–¥–Ω—è (–µ—Å–ª–∏ –≤ –º–∞—Ç—Ä–∏—Ü–µ —É–∂–µ –µ—Å—Ç—å —Å–µ–≥–æ–¥–Ω—è)
        start = last_available
        end = last_available
    elif period_days == 1: # –≤—á–µ—Ä–∞
        yday = dt.date.today() - dt.timedelta(days=1)
        if yday in set(all_days):
            start = end = yday
        else:
            # —Ñ–æ–ª–±—ç–∫: –ø–æ—Å–ª–µ–¥–Ω—è—è –¥–æ—Å—Ç—É–ø–Ω–∞—è –¥–∞—Ç–∞ ‚â§ –≤—á–µ—Ä–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
            candidates = [d for d in all_days if d <= yday]
            if candidates:
                end = start = max(candidates)
            else:
                end = start = last_available
    else:
        end = last_available
        start = end - dt.timedelta(days=days - 1)

    allowed = _allowed_sku_set()
    result: Dict[int, Tuple[float, float]] = {}
    for sku, dmap in matrix.items():
        if allowed and sku not in allowed:
            continue
        u_sum = r_sum = 0.0
        for d, (u, r) in dmap.items():
            if start <= d <= end:
                u_sum += u
                r_sum += r
        if u_sum > 0 or r_sum > 0:
            result[sku] = (u_sum, r_sum)
    return result

def _format_list(agg: Dict[int,                     Tuple[float,                     float]],                     metric: str) -> Tuple[List[str], float, float, float, int]:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫–∏ —Å–ø–∏—Å–∫–∞ –≤ –ø–æ—Ä—è–¥–∫–µ WATCH_SKU. –ù–µ –≤—ã–≤–æ–¥–∏—Ç SKU –±–µ–∑ –∞–ª–∏–∞—Å–∞.
    –ò—Ç–æ–≥–∏ —Å—á–∏—Ç–∞–µ–º –ø–æ —Ç–µ–º –∂–µ –Ω–∞–±–ª—é–¥–∞–µ–º—ã–º SKU, —á—Ç–æ–±—ã —Å—É–º–º—ã —Å–æ–≤–ø–∞–¥–∞–ª–∏ —Å –≤–∏–¥–∏–º—ã–º —Å–ø–∏—Å–∫–æ–º.
    
    Args:
        agg: –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ {sku: (units, revenue)}
        metric: –ú–µ—Ç—Ä–∏–∫–∞ –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è ("units" | "revenue" | "avgprice")
    
    Returns:
        Tuple (lines, total_units, total_revenue, total_avgprice, count_avgprice)
    """
    lines: List[str] = []
    order = _watch_skus_order_list()
    # –ò—Ç–æ–≥–∏ —Ç–æ–ª—å–∫–æ –ø–æ –Ω–∞–±–ª—é–¥–∞–µ–º—ã–º –≤ –Ω—É–∂–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
    tot_u = sum((agg.get(s, (0.0, 0.0))[0] for s in order))
    tot_r = sum((agg.get(s, (0.0, 0.0))[1] for s in order))

    sum_ap = 0.0
    cnt_ap = 0

    for sku in order:
        if sku not in agg:
            continue
        alias = get_alias_for_sku(sku)
        if not alias:
            continue
        u, r = agg[sku]
        if metric == "units":
            lines.append(f"üîπ {alias}: {_fmt_units(u)}")
        elif metric == "revenue":
            lines.append(f"üîπ {alias}: {_fmt_money(r)}")
        elif metric == "avgprice":
            ap = (r / u) if u > 0 else 0.0
            lines.append(f"üîπ {alias}: {_fmt_money(ap)}")
            sum_ap += ap
            cnt_ap += 1

    return lines, tot_u, tot_r, sum_ap, cnt_ap

def _normalize_metric(metric: Optional[str]) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏.
    
    Args:
        metric: –ú–µ—Ç—Ä–∏–∫–∞ ("units" | "revenue" | "avgprice" | ...)
    
    Returns:
        –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä ("units" | "revenue" | "avgprice")
    """
    m = (metric or "units").strip().lower()
    if m in {"avg_price", "avgprice", "avg_check", "avgcheck", "avg",
             "avg_receipt", "average_check", "avg_ticket"}:
        return "avgprice"
    if m in {"revenue", "rev", "money", "gmv"}:
        return "revenue"
    return "units"

async def facts_text(period_days: int, metric: str = "units", force_update: bool = False) -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á—ë—Ç –ø–æ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º –ø—Ä–æ–¥–∞–∂–∞–º.
    
    Args:
        period_days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π (0 - —Å–µ–≥–æ–¥–Ω—è, 1 - –≤—á–µ—Ä–∞, >1 - –ø–µ—Ä–∏–æ–¥)
        metric: –ú–µ—Ç—Ä–∏–∫–∞ ("units" | "revenue" | "avgprice")
        force_update: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–µ–∑ –∫—ç—à–∞
    
    Returns:
        –°—Ç—Ä–æ–∫–∞ —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –æ—Ç—á—ë—Ç–æ–º
    """
    metric_norm = _normalize_metric(metric)
    head_metric = {"units": "–Æ–ù–ò–¢–´", "revenue": "–í–´–†–£–ß–ö–ê", "avgprice": "–°–†–ï–î–ù–ò–ô –ß–ï–ö"}[metric_norm]

    head = f"üìÑ –§–∞–∫—Ç –ø—Ä–æ–¥–∞–∂ ‚Äî {head_metric}\n‚è± –û–±–Ω–æ–≤–ª–µ–Ω–æ: {_now_stamp()}\n"
    label = _period_label_fact(int(period_days))

    agg = await get_facts_aggregated(period_days=int(period_days), force_update=force_update)
    lines, tot_u, tot_r, sum_ap, cnt_ap = _format_list(agg, metric_norm)

    if not lines:
        lines = ["‚Äî"]

    if metric_norm == "units":
        total_line = f"üìä –ò–¢–û–ì–û ‚Äî {_fmt_units(tot_u)}"
    elif metric_norm == "revenue":
        total_line = f"üìä –ò–¢–û–ì–û ‚Äî {_fmt_money(tot_r)}"
    else:
        avg_all = (sum_ap / cnt_ap) if cnt_ap > 0 else 0.0
        total_line = f"üìä –°–†–ï–î–ù–ï–ï ‚Äî {_fmt_money(avg_all)}"

    return "\n".join([head, label, ""] + lines + ["", total_line])
